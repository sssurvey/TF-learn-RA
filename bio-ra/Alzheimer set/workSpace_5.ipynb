{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time as t\n",
    "from pylab import rcParams\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "    \"\"\"\n",
    "    load data from the file path\n",
    "    factory function\n",
    "    \"\"\"\n",
    "    #data_long = pd.read_excel(\"/Users/dilruba_p/Desktop/dataset_576_long.xlsx\") #Dilruba mac\n",
    "    data_long = pd.read_excel(\"/Users/haominshi/Desktop/al_data/dataset_576_long.xlsx\") #Haomin mac\n",
    "    #data_long = pd.read_excel(\"/home/haomin/Desktop/bio-data/dataset_576_long.xlsx\") # thinkpad ubuntu\n",
    "    df = data_long.copy()\n",
    "    print(\"Finish Reading Data /dataset_576_long.xlsx\")\n",
    "    return df\n",
    "\n",
    "def removeNoise(df):\n",
    "    \"\"\"\n",
    "    Argument = df\n",
    "    return = df\n",
    "    \n",
    "    drop some noise of the that might pollute the result\n",
    "    \"\"\"\n",
    "    #medications with analgesic_rx\n",
    "    #df = df[df.analgesic_rx !=1]\n",
    "    #removing people who have a suspected of having head injuries in past visits \n",
    "    #df = df[df.headinjrloc_cum !=1]\n",
    "    #removing people who have a suspected of having cancer in past visits \n",
    "    #df = df[df.cancer_cum !=1]\n",
    "    #removing people who have a suspected of having diabetes in past visits \n",
    "    df = df[df.dm_cum !=1]\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def groupbyid(df):\n",
    "    \"\"\"\n",
    "    arg = df\n",
    "    return = list of df\n",
    "    \n",
    "    convert the df to a list of df that is grouped by the patient id\n",
    "    return a list of df\n",
    "    \"\"\"\n",
    "    # convert the values from the projid to a list\n",
    "    projid_all = df.projid.unique()\n",
    "    projid_list = projid_all.tolist() # a unique list of ID  acquired \n",
    "\n",
    "    patient_dfbyid = []\n",
    "    start_df_row = 0 # selecting the first row \n",
    "    end_df_row   = 0 # selecting the last row\n",
    "    flag_start   = 0 # start index for df spliting based on unique ID\n",
    "    df = df.reset_index(drop = True) # df reindexed\n",
    "\n",
    "    for p_id in projid_all: # loop through the unique id list\n",
    "        for df_index in range(flag_start, df.shape[0]): \n",
    "            if df.iloc[df_index]['projid'] == p_id: end_df_row += 1\n",
    "            elif df.iloc[df_index]['projid'] != p_id: break\n",
    "        patient_dfbyid.append(df[start_df_row: end_df_row])\n",
    "        start_df_row = end_df_row\n",
    "        flag_start = end_df_row\n",
    "\n",
    "    return patient_dfbyid # a list of df, that each element of the list is one patient\n",
    "\n",
    "def patient_diagnosis(list_of_patient):\n",
    "    \"\"\"\n",
    "    arg = list\n",
    "    return list\n",
    "    \n",
    "    This function split the patient list to 2 sub list, each of them contain a whole DF for that patient\n",
    "    The difference is that one list is for patient that is diagonsed in future, the other is not\n",
    "    it is splif via the dcfdx value, dcfdx >= 3 means diagnosed\n",
    "    \"\"\"\n",
    "\n",
    "    patient_dfbyid_diagnosed = []      #  diagnosed with alzheimer\n",
    "    patient_dfbyid_not_diagnosed = []  # not diagnalzheimer\n",
    "    diagonosed = False\n",
    "\n",
    "    for patient in list_of_patient:\n",
    "        dcfdx_list = patient['dcfdx'].tolist()\n",
    "        for dcfdx_element in dcfdx_list:\n",
    "            if dcfdx_element >= 3: # >= 4 means diagnoised\n",
    "                diagonosed = True\n",
    "                break\n",
    "        if (diagonosed) == True:\n",
    "            patient_dfbyid_diagnosed.append(patient)\n",
    "            diagonosed= False\n",
    "        else: patient_dfbyid_not_diagnosed.append(patient)\n",
    "    \n",
    "    return patient_dfbyid_diagnosed, patient_dfbyid_not_diagnosed\n",
    "\n",
    "def appending_initial_df_to_full_df(list_of_df):\n",
    "    \"\"\"\n",
    "    argument = list\n",
    "    return = df\n",
    "    \n",
    "    This list takes in a list of dataframe and appending the first df to achieve concat, it returns\n",
    "    the first df at the end\n",
    "    \"\"\"\n",
    "    list_of_df_copy = list_of_df[:]\n",
    "    counter = 0\n",
    "    for df in list_of_df_copy[1:]:\n",
    "        counter+=1\n",
    "        print(\"appending{}\".format(counter))\n",
    "        list_of_df_copy[0] = list_of_df_copy[0].append(df, ignore_index=True)\n",
    "    return list_of_df_copy[0]\n",
    "\n",
    "def imputemean_per_id(list_of_df_temp,focus = \"crn\"):\n",
    "    for df in list_of_df_temp:\n",
    "        M = df[focus].mean()\n",
    "        df[focus].fillna(M,inplace=True)\n",
    "    return list_of_df_temp\n",
    "\n",
    "def some_cleaning(listOfDf):\n",
    "    \"\"\"\n",
    "    with special focus on certain columns, if any of these columns in the data is nan\n",
    "    the row with that column is dropped, column comes form the string in the method\n",
    "    \n",
    "    argumnet = list\n",
    "    return = list\n",
    "    \"\"\"\n",
    "    feature_str = \\\n",
    "    \"chlstrl gfr_mdrs glucose hdlchlstrl ldlchlstrl cogn_global cts_fruits cts_idea cts_sdmt iadlsum katzsum rosbscl rosbsum phys5itemsum\"\n",
    "    label = \"dcfdx\"\n",
    "    \n",
    "    #feature_str = \\\n",
    "    #\"gfr_mdrs cogn_global cts_fruits cts_idea cts_sdmt iadlsum rosbsum\"\n",
    "    #label = \"dcfdx\"\n",
    "    \n",
    "    feature_item_list = feature_str.split(\" \")\n",
    "    # only pick rows that have these values\n",
    "    test_list_patient = patient_visit_list[:]\n",
    "    for df in test_list_patient:\n",
    "        for feature in feature_item_list:\n",
    "            df = df[np.isfinite(df[feature])]\n",
    "    return test_list_patient\n",
    "\n",
    "def getInterval(list_df):\n",
    "    alltogether = \"chlstrl gfr_mdrs glucose hdlchlstrl ldlchlstrl cogn_global cts_fruits cts_idea cts_sdmt iadlsum katzsum rosbscl rosbsum phys5itemsum\"\\\n",
    "    .split(\" \")\n",
    "    the_dict = {}\n",
    "    newlist = []\n",
    "    for patient in list_df:\n",
    "        for column_names in alltogether:\n",
    "            newlist.append(patient.iloc[-1][column_names] - patient.iloc[0][column_names])\n",
    "        the_dict[patient.iloc[0]['projid']] = newlist\n",
    "        newlist = []\n",
    "    return the_dict\n",
    "\n",
    "def fillNaNs(list_of_df):\n",
    "    for df in list_of_df:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Reading Data /dataset_576_long.xlsx\n",
      "Done 1\n",
      "(25570, 203)\n",
      "(21254, 203)\n",
      "Done 2\n",
      "Done 3\n",
      "841 amount people diagnosed, 2048 amount of people not diagnosed\n",
      "2889 total patient amount\n",
      "Cell finished\n",
      "(21254, 203)\n"
     ]
    }
   ],
   "source": [
    "raw_dataframe = readData() # load excel to df\n",
    "print(\"Done 1\")\n",
    "print(raw_dataframe.shape)\n",
    "noise_removed_dataframe = removeNoise(raw_dataframe) # remove some noise\n",
    "print(\"Done 2\")\n",
    "patient_visit_list = groupbyid(noise_removed_dataframe) # put df to a list grouped by patient id\n",
    "print(\"Done 3\")\n",
    "patient_diagnosed, patient_not_diagnosed = patient_diagnosis(patient_visit_list)\n",
    "print(\"{} amount people diagnosed, {} amount of people not diagnosed\"\\\n",
    "      .format(len(patient_diagnosed), len(patient_not_diagnosed)))\n",
    "print(\"{} total patient amount\".format(len(patient_visit_list)))\n",
    "print(\"Cell finished\")\n",
    "\n",
    "print(noise_removed_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns = ['chlstrl','crn','gfr_mdrs','glucose','hba1c','hdlchlstrl', 'hdlratio','hemacrit','hemoglbn',\n",
    "'ldlchlstrl', 'mch', 'mchc', 'mcv', 'platelet','rbc', 'dcfdx', 'projid', 'age_at_visit'] \n",
    "# these are the columns that we are interesed in, However, right now i dont have a good idea about what value I\n",
    "# should be use to replace the NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One of the approach we have is to replace the NaNs with local mean of that column value based on that patient's visit. Personally, I dont think that is a good idea. Certainly, if a patient have dcfdx span from 1 to 4, the mean then lost its meanings.__\n",
    "\n",
    "Check the diabieties, how?\n",
    "1. Person is in first visit, and he/she does not have AD and D\n",
    "2. Person is in second visit, current they have dcfdx == 4, we want to see next visit if they have D\n",
    "3. Person is in third or more visit, with AD already diagnosed check if they have D\n",
    "\n",
    "Some special trails:\n",
    "1. I tried not to drop anyone who is diagnosed with Ob but this seems not really affect the outcome, even tho the original sample size is much larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2889 original len\n",
      "702 stage 1 clean\n",
      "33 stage 2 clean\n",
      "349 stage 3 clean\n"
     ]
    }
   ],
   "source": [
    "# some experiments\n",
    "print(\"{} original len\".format(len(patient_visit_list)))\n",
    "def check_dcfdx_dP_clean_1(patient_list_id):\n",
    "    \"\"\"\n",
    "    check if there is a relation between poeple who have AD and D\n",
    "    bmi 25, 30 this is overweight\n",
    "    bmi 30, 40 this is ob\n",
    "    bmi 40 + this is very ob\n",
    "    \"\"\"\n",
    "    return_list_of_patent = []\n",
    "    for patient in patient_list_id:\n",
    "        if patient.iloc[0]['dcfdx'] == 1 and patient.iloc[0]['bmi'] < 25:\n",
    "            return_list_of_patent.append(patient)\n",
    "            continue # skip to next patient\n",
    "    return return_list_of_patent\n",
    "\n",
    "def check_dcfdx_dp_clean_2(patient_list_id):\n",
    "    return_list_of_patent = []\n",
    "    for patient in patient_list_id:\n",
    "        for row_index in range(patient.shape[0]):\n",
    "            if patient.iloc[row_index]['dcfdx'] >= 4 and patient.iloc[row_index]['bmi'] >= 25:\n",
    "                return_list_of_patent.append(patient)\n",
    "                break # no need to scan if found\n",
    "    return return_list_of_patent\n",
    "\n",
    "def check_dcfdx_dp_clean_special(patient_list_id):\n",
    "    return_list_of_patent = []\n",
    "    for patient in patient_list_id:\n",
    "        for row_index in range(patient.shape[0]):\n",
    "            if patient.shape[0] < 3:\n",
    "                break # dont care about patient has less visit than 3\n",
    "            if patient.iloc[row_index]['dcfdx'] >= 4 and patient.iloc[row_index]['bmi'] >= 25:\n",
    "                return_list_of_patent.append(patient)\n",
    "                break # no need to scan if found\n",
    "    return return_list_of_patent\n",
    "\n",
    "\n",
    "test_list_stage1 = check_dcfdx_dP_clean_1(patient_visit_list)\n",
    "print(\"{} stage 1 clean\".format(len(test_list_stage1)))\n",
    "test_list_stage2 = check_dcfdx_dp_clean_2(test_list_stage1)\n",
    "print(\"{} stage 2 clean\".format(len(test_list_stage2)))\n",
    "test_list_stage_special = check_dcfdx_dp_clean_special(patient_visit_list)\n",
    "print(\"{} stage 3 clean\".format(len(test_list_stage_special)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_patient_list = some_cleaning(patient_visit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are total 2889 patient, within that there are 818 people was dcfdx >= 4 ignore previous record, \n",
      " that is 28.314295604015232 %\n",
      "there are total 2889 patient, within that there are 283 people was dcfdx <= 3 to dcfdx >= 4, \n",
      " that is 9.795777085496711 %\n",
      "there are total 2889 patient, within that there are 355 people was dcfdx == 1 to dcfdx >= 4, \n",
      " that is 12.287988923502942 %\n",
      "there are total 2889 patient, within that there are 653 in explore function, \n",
      " that is 22.602976808584284 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate counter and the percentage of ppl that is sick\n",
    "counter = 0\n",
    "\n",
    "for patient in focus_patient_list:\n",
    "    for row_number in range(patient.shape[0]):\n",
    "        if patient.iloc[row_number]['dcfdx'] >= 4:\n",
    "            counter+=1\n",
    "            break\n",
    "                \n",
    "print(\"there are total {} patient, within that there are {} people was dcfdx >= 4 ignore previous record, \\n that is {} %\"\\\n",
    "     .format(len(focus_patient_list), counter, counter/len(focus_patient_list) * 100))\n",
    "\n",
    "counter = 0\n",
    "for patient in focus_patient_list:\n",
    "    for row_number in range(patient.shape[0]):\n",
    "        if patient.iloc[0]['dcfdx'] == 2:\n",
    "            if patient.iloc[row_number]['dcfdx'] >= 4:\n",
    "                counter+=1\n",
    "                break\n",
    "print(\"there are total {} patient, within that there are {} people was dcfdx <= 3 to dcfdx >= 4, \\n that is {} %\"\\\n",
    "     .format(len(focus_patient_list), counter, counter/len(focus_patient_list) * 100))\n",
    "\n",
    "counter = 0\n",
    "for patient in focus_patient_list:\n",
    "    for row_number in range(patient.shape[0]):\n",
    "        if patient.iloc[0]['dcfdx'] == 1:\n",
    "            if patient.iloc[row_number]['dcfdx'] >= 4:\n",
    "                counter+=1\n",
    "                break\n",
    "print(\"there are total {} patient, within that there are {} people was dcfdx == 1 to dcfdx >= 4, \\n that is {} %\"\\\n",
    "     .format(len(focus_patient_list), counter, counter/len(focus_patient_list) * 100))\n",
    "\n",
    "# some explore\n",
    "\n",
    "counter = 0\n",
    "for patient in focus_patient_list:\n",
    "    for row_number in range(patient.shape[0]):\n",
    "        if patient.shape[0] > 2:\n",
    "            if patient.iloc[0]['dcfdx'] <= 2 or patient.iloc[1]['dcfdx'] <= 2 or patient.iloc[2]['dcfdx'] <= 2:\n",
    "                if patient.iloc[row_number]['dcfdx'] >= 4:\n",
    "                    counter+=1\n",
    "                    break\n",
    "print(\"there are total {} patient, within that there are {} in explore function, \\n that is {} %\"\\\n",
    "     .format(len(focus_patient_list), counter, counter/len(focus_patient_list) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train prep\n",
    "Reuse the previous functions from the last cell, I will construct 3 dataframes, each of the dataframe represent one possible route:\n",
    "1. not diagnosed (past) -> diagnosed (now)\n",
    "2. not diagnosed (past) -> not diagnosed (now)\n",
    "3. diagnosed (past) -> diagnosed (now)\n",
    "\n",
    "First, construct the dataframe, than use 70% of each of the df to train, 20% to test, 10% to validate, __current plan__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_nd_nd DONE!\n",
      "df_nd_d DONE!\n",
      "df_d_d DONE!\n",
      "0        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "5        1.0\n",
      "6        1.0\n",
      "7        1.0\n",
      "12       1.0\n",
      "13       1.0\n",
      "14       1.0\n",
      "15       1.0\n",
      "16       1.0\n",
      "17       1.0\n",
      "18       1.0\n",
      "19       1.0\n",
      "43       1.0\n",
      "46       1.0\n",
      "47       1.0\n",
      "48       1.0\n",
      "49       1.0\n",
      "50       1.0\n",
      "51       1.0\n",
      "52       1.0\n",
      "53       1.0\n",
      "54       1.0\n",
      "55       1.0\n",
      "56       1.0\n",
      "57       1.0\n",
      "58       1.0\n",
      "66       1.0\n",
      "        ... \n",
      "21201    1.0\n",
      "21203    1.0\n",
      "21204    1.0\n",
      "21205    1.0\n",
      "21206    1.0\n",
      "21207    1.0\n",
      "21208    1.0\n",
      "21209    1.0\n",
      "21210    1.0\n",
      "21211    1.0\n",
      "21212    1.0\n",
      "21213    1.0\n",
      "21214    2.0\n",
      "21215    1.0\n",
      "21216    1.0\n",
      "21228    1.0\n",
      "21229    1.0\n",
      "21230    1.0\n",
      "21231    1.0\n",
      "21232    1.0\n",
      "21233    1.0\n",
      "21234    1.0\n",
      "21235    1.0\n",
      "21237    1.0\n",
      "21238    1.0\n",
      "21239    1.0\n",
      "21240    1.0\n",
      "21242    1.0\n",
      "21243    1.0\n",
      "21252    1.0\n",
      "Name: dcfdx, Length: 3843, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def create3dfs (focus_patient_list):\n",
    "    work_list_this_fn = focus_patient_list[:] # set up\n",
    "    # first loop to concat the nd - nd\n",
    "    feature_str = \\\n",
    "    \"projid dcfdx chlstrl gfr_mdrs glucose hdlchlstrl ldlchlstrl cogn_global cts_fruits cts_idea cts_sdmt iadlsum katzsum rosbscl rosbsum phys5itemsum\"\n",
    "    # label = \"dcfdx\"\n",
    "    feature_str_list = feature_str.split(\" \")\n",
    "    df_nd_nd = pd.DataFrame(columns=feature_str_list) # new df with only the feature str created\n",
    "    df_nd_d = pd.DataFrame(columns=feature_str_list)\n",
    "    df_d_d = pd.DataFrame(columns=feature_str_list)\n",
    "    \n",
    "    # changed it to not so wrong...\n",
    "    for patient in work_list_this_fn: # ND ND\n",
    "        if int(patient[\"dcfdx\"].sum())/int(patient.shape[0]) > 1:\n",
    "            pass\n",
    "        else:\n",
    "            df_nd_nd = df_nd_nd.append(patient[feature_str_list])\n",
    "        \n",
    "                \n",
    "    print(\"df_nd_nd DONE!\")\n",
    "    for patient in work_list_this_fn: # ND D\n",
    "        for row_number in range(patient.shape[0]):\n",
    "            if patient.shape[0] > 2:\n",
    "                if patient.iloc[0]['dcfdx'] <= 2 \\\n",
    "                or patient.iloc[1]['dcfdx'] <= 2 \\\n",
    "                or patient.iloc[2]['dcfdx'] <= 2:\n",
    "                    if patient.iloc[row_number]['dcfdx'] >= 4:\n",
    "                        df_nd_d = df_nd_d.append(patient[feature_str_list])\n",
    "                        break\n",
    "                        \n",
    "    print(\"df_nd_d DONE!\")\n",
    "    for patient in work_list_this_fn: # D D\n",
    "        if patient.iloc[0]['dcfdx'] > 3:\n",
    "            df_d_d = df_d_d.append(patient[feature_str_list])\n",
    "    print(\"df_d_d DONE!\")\n",
    "                \n",
    "    return df_nd_nd, df_nd_d, df_d_d\n",
    "\n",
    "train_nd_nd, train_nd_d, train_d_d = create3dfs(focus_patient_list)\n",
    "\n",
    "def removeNanRow(df):\n",
    "    \"\"\"remove all the rows that has Nan in it\"\"\"\n",
    "    feature_str = \\\n",
    "    \"dcfdx chlstrl gfr_mdrs glucose hdlchlstrl ldlchlstrl cogn_global cts_fruits cts_idea cts_sdmt iadlsum katzsum rosbscl rosbsum phys5itemsum\"\n",
    "    # label = \"dcfdx\"\n",
    "    feature_str_list = feature_str.split(\" \")\n",
    "    for feature in feature_str_list:\n",
    "        df = df[np.isfinite(df[feature])]\n",
    "    return df\n",
    "\n",
    "train_nd_nd = removeNanRow(train_nd_nd)\n",
    "train_nd_d = removeNanRow(train_nd_d)\n",
    "train_d_d = removeNanRow(train_d_d)\n",
    "\n",
    "\n",
    "print(train_nd_nd[\"dcfdx\"])\n",
    "#print(train_nd_d.head())\n",
    "#print(train_d_d.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_list = groupbyid(train_nd_d)\n",
    "#print(a_new_list[0])\n",
    "\n",
    "\n",
    "\n",
    "result = getInterval(a_new_list)\n",
    "print(result[285563])\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
